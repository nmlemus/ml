[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Machine learning is a rapidly growing field that enables computers to learn from data, without being explicitly programmed. The goal of machine learning is to build models that can make predictions or take actions based on input data, and improve their performance over time through experience."
  },
  {
    "objectID": "index.html#overview-of-machine-learning",
    "href": "index.html#overview-of-machine-learning",
    "title": "Machine Learning",
    "section": "Overview of Machine Learning:",
    "text": "Overview of Machine Learning:\nMachine learning is a subfield of artificial intelligence that involves the development of algorithms and statistical models that allow computers to learn from data. There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.\nSupervised learning is the most common type of machine learning, in which a model is trained on a labeled dataset to make predictions about new, unseen data. Examples include linear regression, logistic regression, and decision trees.\nUnsupervised learning involves discovering patterns in unlabeled data, such as clustering and dimensionality reduction.\nReinforcement learning involves training an agent to make decisions in an environment to maximize a reward."
  },
  {
    "objectID": "index.html#applications-of-machine-learning",
    "href": "index.html#applications-of-machine-learning",
    "title": "Machine Learning",
    "section": "Applications of Machine Learning",
    "text": "Applications of Machine Learning\nMachine learning has many applications in various industries, including:\n\nHealthcare: for example, identifying potential health risks, diagnosing diseases, and creating personalized treatment plans\nFinance: for example, detecting fraudulent transactions, predicting stock prices, and identifying potential investment opportunities\nRetail: for example, personalizing product recommendations, optimizing pricing strategies, and improving supply chain efficiency\nManufacturing: for example, predictive maintenance, quality control, and optimization of production processes\nTransportation: for example, traffic prediction, autonomous driving, and fleet management\nCybersecurity: for example, intrusion detection, anomaly detection, and threat intelligence"
  },
  {
    "objectID": "index.html#key-concepts-and-terminology",
    "href": "index.html#key-concepts-and-terminology",
    "title": "Machine Learning",
    "section": "Key Concepts and Terminology",
    "text": "Key Concepts and Terminology\nMachine learning is a complex field with many technical terms and concepts. Some key terms and concepts that will be covered in this book include:\n\nModel: a representation of the relationships between input data and output predictions or actions\nTraining: the process of fitting a model to a dataset\nTesting: the process of evaluating a model on new, unseen data\nOverfitting: when a model is too complex and performs well on the training data but poorly on the test data\nRegularization: a technique for preventing overfitting by adding a penalty term to the model’s objective function\nGradient descent: an optimization algorithm for finding the minimum of a function\nNeural networks: a type of model that is inspired by the structure and function of the human brain\nConvolutional neural networks (CNNs): a type of neural network designed for image recognition\nRecurrent neural networks (RNNs): a type of neural network designed for sequential data such as time series and natural language."
  },
  {
    "objectID": "index.html#versions-used-in-this-book",
    "href": "index.html#versions-used-in-this-book",
    "title": "Machine Learning",
    "section": "Versions Used in this Book",
    "text": "Versions Used in this Book\n\n\nCode\nimport sys\nprint(\"Python version: {}\".format(sys.version))\nimport pandas as pd\nprint(\"pandas version: {}\".format(pd.__version__))\nimport matplotlib\nprint(\"matplotlib version: {}\".format(matplotlib.__version__))\nimport numpy as np\nprint(\"NumPy version: {}\".format(np.__version__))\nimport scipy as sp\nprint(\"SciPy version: {}\".format(sp.__version__))\nimport IPython\nprint(\"IPython version: {}\".format(IPython.__version__))\nimport sklearn\nprint(\"scikit-learn version: {}\".format(sklearn.__version__))\n\n\nPython version: 3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]\npandas version: 1.4.4\nmatplotlib version: 3.5.2\nNumPy version: 1.21.5\nSciPy version: 1.9.1\nIPython version: 7.31.1\n\n\nscikit-learn version: 1.0.2"
  },
  {
    "objectID": "fundamentals/fundamentals.html#probability-and-statistics",
    "href": "fundamentals/fundamentals.html#probability-and-statistics",
    "title": "1  Fundamentals of Machine Learning",
    "section": "1.1 Probability and Statistics",
    "text": "1.1 Probability and Statistics\n\n1.1.1 Introduction to Probability\n\n1.1.1.1 Definition of probability\nProbability is a measure of the likelihood of an event occurring. It is a value between 0 and 1, where 0 indicates that an event will never occur and 1 indicates that an event will always occur.\nProbability can be defined in different ways, but one of the most common ways is through the use of relative frequency. If we repeat an experiment many times and count the number of times an event of interest occurs, we can calculate the probability of that event as the ratio of the number of successful outcomes to the total number of trials. For example, if we flip a coin 10 times and it comes up heads 6 times, we can say that the probability of getting heads is 6/10 or 0.6.\nProbability can also be defined through the use of theoretical models. For example, in the coin flipping example, we can assume that the coin is fair and that the probability of getting heads is 0.5.\nProbability can be applied to many different types of events and situations, such as in gambling, finance, weather forecasting, medical diagnosis, and many more. In machine learning, probability is used to model the uncertainty of predictions, estimate model parameters and evaluate model performance.\n\n\n1.1.1.2 Random variables and events\nA random variable is a variable that takes on different values based on the outcome of a random experiment. The values of a random variable can be numerical or categorical, and the probability of each value is defined by a probability distribution.\nFor example, in a coin-tossing experiment, the random variable X can take on the values of “heads” or “tails”. The probability of getting heads is 0.5, and the probability of getting tails is also 0.5. We can represent the probability distribution of X in a table or a graph.\nAn event is a set of outcomes from a random experiment. For example, in a coin-tossing experiment, the event “getting heads” is the set {heads}, and the event “getting tails” is the set {tails}.\nA random variable is said to be discrete if it can take on only a countable number of values and continuous if it can take on any value in an interval.\nFor example, in a dice-rolling experiment, the random variable X can take on the values 1, 2, 3, 4, 5, or 6. X is a discrete random variable.\nOn the other hand, in a temperature measurement experiment, the random variable X can take on any value between -273.15 and infinity (the absolute zero and the maximum temperature). X is a continuous random variable.\nIn machine learning, random variables are used to represent the input and output of a model, the parameters of a model and the noise in the data. Understanding the properties of random variables and the events they can generate is important to design and analyze machine learning algorithms.\n\n\n1.1.1.3 Sample space and event space\n\n\n1.1.1.4 Axioms of probability"
  },
  {
    "objectID": "fundamentals/fundamentals.html#linear-algebra",
    "href": "fundamentals/fundamentals.html#linear-algebra",
    "title": "1  Fundamentals of Machine Learning",
    "section": "1.2 Linear Algebra",
    "text": "1.2 Linear Algebra"
  },
  {
    "objectID": "fundamentals/fundamentals.html#optimization",
    "href": "fundamentals/fundamentals.html#optimization",
    "title": "1  Fundamentals of Machine Learning",
    "section": "1.3 Optimization",
    "text": "1.3 Optimization"
  },
  {
    "objectID": "fundamentals/fundamentals.html#data-preprocessing-and-feature-engineering",
    "href": "fundamentals/fundamentals.html#data-preprocessing-and-feature-engineering",
    "title": "1  Fundamentals of Machine Learning",
    "section": "1.4 Data Preprocessing and Feature Engineering",
    "text": "1.4 Data Preprocessing and Feature Engineering"
  },
  {
    "objectID": "supervised/supervised_learning.html",
    "href": "supervised/supervised_learning.html",
    "title": "Supervised Learning",
    "section": "",
    "text": "Supervised learning is a type of machine learning where the model is trained on labeled data, where the desired output is provided for each input. The goal of supervised learning is to learn a mapping from inputs to outputs, so that the model can make predictions on new, unseen data.\nSupervised learning can be further divided into two categories: regression and classification. In regression, the output variable is continuous, and the goal is to predict a numerical value. For example, predicting the price of a house based on its square footage. In classification, the output variable is categorical, and the goal is to predict a class label. For example, classifying an email as spam or not spam.\nSupervised learning algorithms can be linear or non-linear, parametric or non-parametric, and they can be based on different assumptions and mathematical models. Some examples of supervised learning algorithms are linear regression, logistic regression, decision trees, k-nearest neighbors, and neural networks.\nSupervised learning is widely used in many applications, such as image and speech recognition, natural language processing, and predictive modeling. In this section, we will discuss the fundamentals of supervised learning, including the types of problems it can solve, the evaluation metrics used to measure its performance, and the algorithms and techniques used to solve those problems."
  },
  {
    "objectID": "supervised/linear_regression.html#learning-by-examples",
    "href": "supervised/linear_regression.html#learning-by-examples",
    "title": "2  Linear Regression",
    "section": "2.1 Learning by Examples",
    "text": "2.1 Learning by Examples\nFor this example, we will be using salary data from Kaggle. The data consists of two columns, years of experience and the corresponding salary. The data can be downloaded from here.\n\n\n\n\n\n\n  \n    \n      \n      YearsExperience\n      Salary\n    \n  \n  \n    \n      0\n      1.1\n      39343.0\n    \n    \n      1\n      1.3\n      46205.0\n    \n    \n      2\n      1.5\n      37731.0\n    \n    \n      3\n      2.0\n      43525.0\n    \n    \n      4\n      2.2\n      39891.0\n    \n  \n\n\n\n\n\n\nCode\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"notebook+pdf\"\npio.kaleido.scope.default_format = \"png\"\ndf = px.data.iris()\nfig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", \n                 color=\"species\", \n                 marginal_y=\"violin\", marginal_x=\"box\", \n                 trendline=\"ols\", template=\"simple_white\")\nfig.show()\n\n\n\n                                                \n\n\n\n\n\n\n\nFigure 2.1: Simple Plot"
  },
  {
    "objectID": "unsupervised/unsupervised_learning.html#clustering",
    "href": "unsupervised/unsupervised_learning.html#clustering",
    "title": "7  Unsupervised Learning",
    "section": "7.1 Clustering",
    "text": "7.1 Clustering"
  },
  {
    "objectID": "unsupervised/unsupervised_learning.html#dimensionality-reduction",
    "href": "unsupervised/unsupervised_learning.html#dimensionality-reduction",
    "title": "7  Unsupervised Learning",
    "section": "7.2 Dimensionality Reduction",
    "text": "7.2 Dimensionality Reduction"
  },
  {
    "objectID": "unsupervised/unsupervised_learning.html#anomaly-detection",
    "href": "unsupervised/unsupervised_learning.html#anomaly-detection",
    "title": "7  Unsupervised Learning",
    "section": "7.3 Anomaly Detection",
    "text": "7.3 Anomaly Detection"
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "16  Conclusion",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "ref_appendices/appendices.html#mathematical-proofs",
    "href": "ref_appendices/appendices.html#mathematical-proofs",
    "title": "Appendix A — Appendices",
    "section": "A.1 Mathematical Proofs",
    "text": "A.1 Mathematical Proofs"
  },
  {
    "objectID": "ref_appendices/appendices.html#additional-resources",
    "href": "ref_appendices/appendices.html#additional-resources",
    "title": "Appendix A — Appendices",
    "section": "A.2 Additional Resources",
    "text": "A.2 Additional Resources"
  }
]